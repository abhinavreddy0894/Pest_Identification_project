{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Loss: 0.9774919096110524\n",
      "Epoch 2/15, Loss: 0.5311626286610313\n",
      "Epoch 3/15, Loss: 0.4716291250526041\n",
      "Epoch 4/15, Loss: 0.4495019508336765\n",
      "Epoch 5/15, Loss: 0.43360744335729146\n",
      "Epoch 6/15, Loss: 0.3987090182153211\n",
      "Epoch 7/15, Loss: 0.40189534101797186\n",
      "Epoch 8/15, Loss: 0.39402336087347806\n",
      "Epoch 9/15, Loss: 0.3866499874038973\n",
      "Epoch 10/15, Loss: 0.37965307449517044\n",
      "Epoch 11/15, Loss: 0.37068800412226416\n",
      "Epoch 12/15, Loss: 0.3679426585634549\n",
      "Epoch 13/15, Loss: 0.37225163576827536\n",
      "Epoch 14/15, Loss: 0.3724978964343883\n",
      "Epoch 15/15, Loss: 0.36834953833317413\n",
      "Test Accuracy: 83.62147406733393%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define data transformations with enhanced augmentations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Path to your external dataset\n",
    "dataset_dir = 'D:\\\\Programs\\\\Jupyter\\\\Pest_data'\n",
    "\n",
    "# Load train and test datasets\n",
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "test_dir = os.path.join(dataset_dir, 'test')\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Update the number of classes dynamically based on the dataset\n",
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "# Define the model with improvements\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.query = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)\n",
    "        self.key = nn.Conv2d(in_channels, in_channels // 8, kernel_size=1)\n",
    "        self.value = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, C, H, W = x.size()\n",
    "        query = self.query(x).view(batch_size, -1, H * W).permute(0, 2, 1)\n",
    "        key = self.key(x).view(batch_size, -1, H * W)\n",
    "        attention = torch.bmm(query, key)\n",
    "        attention = F.softmax(attention, dim=-1)\n",
    "\n",
    "        value = self.value(x).view(batch_size, -1, H * W)\n",
    "        out = torch.bmm(value, attention.permute(0, 2, 1))\n",
    "        out = out.view(batch_size, C, H, W)\n",
    "\n",
    "        out = self.gamma * out + x\n",
    "        return out\n",
    "\n",
    "class PestIdentificationModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(PestIdentificationModel, self).__init__()\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "        \n",
    "        # Freeze initial layers for better fine-tuning\n",
    "        for param in resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        self.resnet_features = nn.Sequential(*list(resnet.children())[:-2])\n",
    "        self.self_attention = SelfAttention(in_channels=2048)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(0.5)  # Dropout to reduce overfitting\n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet_features(x)\n",
    "        x = self.self_attention(x)\n",
    "        x = self.avg_pool(x).view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = PestIdentificationModel(num_classes=num_classes)\n",
    "model = model.cuda()  # Move model to GPU\n",
    "\n",
    "# Define optimizer, loss function, and learning rate scheduler\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
    "\n",
    "# Training loop with improvements\n",
    "epochs = 15\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss}\")\n",
    "    scheduler.step(avg_loss)  # Adjust learning rate based on loss\n",
    "\n",
    "# Test the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
